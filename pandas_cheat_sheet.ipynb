{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Pandas Cheat Sheet</h2>\n",
    "<h3>Topics Covered:</h3>\n",
    "<ul>\n",
    "    <li>Basic CRUD Operation</li>\n",
    "    <li>Viewing DataFrame Info</li>\n",
    "    <li>Regression</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with an example of how regression might be performed for data representing\n",
    "# the price of a stock over time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data into a pandas dataframe\n",
    "df = pd.read_csv('AAPL.csv')\n",
    "\n",
    "# The following lines demonstrate how to perform exploratory data analysis on the data\n",
    "# Print the first 5 rows of the dataframe\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the data types of each column along with the number of non-null values\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Print summary statistics for each column (for numeric columns only)\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Print summary statistics for each column (for non-numeric columns only)\n",
    "print(df.describe(include='object'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Accessing columns in a pandas dataframe - columns are the keys\n",
    "- In many cases, if a column intends to represent dates, the type might need to be cast to datetime\n",
    "- if the type is 'object' it may or may not be in datetime, and may need to be cast as such.\n",
    "- 'YYYY-MM-DD' is the a common format for dates in pandas\n",
    "'''\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# 'Date' column will now be of type datetime64\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access multiple columns by passing a list of column names\n",
    "print(df[['Open', 'Close']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's perform some actual analysis and regression on the data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data = df['Close'][:len(df) - 100]  # closing prices up from beginnning up to last 100 data points\n",
    "test_data = df['Close'][-100:]  # last 100 data points for testing\n",
    "\n",
    "# Create and fit the ARIMA model\n",
    "model = ARIMA(train_data, order=(1, 1, 1))\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Make predictions on the testing data\n",
    "predictions = model_fit.forecast(steps=len(test_data))\n",
    "\n",
    "# Evaluate the model's performance\n",
    "mse = mean_squared_error(test_data, predictions)  # measure average squared difference between actual vs predicted values\n",
    "rmse = np.sqrt(mse)  \n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "\n",
    "# Visualize the actual and predicted stock prices\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_data.index, train_data, label='Training Data')\n",
    "plt.plot(test_data.index, test_data, label='Actual Price')\n",
    "plt.plot(test_data.index, predictions, label='Predicted Price')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Stock Price Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Removing leading/trailing whitespace</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "num_rows = 10\n",
    "\n",
    "# Create a dictionary of data w leading/trailing spaces in column names and values\n",
    "cols = {\n",
    "    'ID': np.arange(num_rows),\n",
    "    '  Programming Langauge   ': np.random.choice(['Java   ', '   Python', ' JavaScript  '], num_rows),\n",
    "    '  Score  ': np.random.randint(60, 100, num_rows)\n",
    "}\n",
    "\n",
    "# Create a dataframe from the dictionary\n",
    "df = pd.DataFrame(cols)\n",
    "\n",
    "# For loop can be used to remove leading/trailing spaces from column names\n",
    "# Removing leading/trailing spaces from all columns\n",
    "df = df.rename(columns={col: col.strip() for col in df.columns})\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# We can also use a lambda expression to perfrom the same operation\n",
    "\n",
    "num_rows = 10\n",
    "\n",
    "# Create a dictionary of data w leading/trailing spaces in column names and values\n",
    "cols = {\n",
    "    'ID': np.arange(num_rows),\n",
    "    '  Programming Langauge   ': np.random.choice(['Java   ', '   Python', ' JavaScript  '], num_rows),\n",
    "    '  Score  ': np.random.randint(60, 100, num_rows)\n",
    "}\n",
    "\n",
    "# Create a dataframe from the dictionary\n",
    "df = pd.DataFrame(cols)\n",
    "\n",
    "# For loop can be used to remove leading/trailing spaces from column names\n",
    "# Removing leading/trailing spaces from all columns\n",
    "df = df.rename(columns=lambda x: x.strip())\n",
    "\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Reading a TSV file</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same steps, only use sep='\\t' to indicate that the data is tab-separated\n",
    "df = pd.read_csv('data.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Reading an Excel file</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic reading\n",
    "pd.read_excel('data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the sheet name\n",
    "pd.read_excel('data.xlsx', sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip rows if necessary\n",
    "pd.read_csv('data.csv', skiprows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sheet names\n",
    "pd.ExcelFile('data.xlsx').sheet_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Basic Statistics</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain min/mean/max of non-obect columns\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of a specific column\n",
    "df['column_name'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate median of a specific column\n",
    "df['column_name'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mode of a specific column\n",
    "df['column_name'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcuate min/max of a specific column\n",
    "df['column_name'].min()\n",
    "df['column_name'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Miscellaneous Data Frame Formatting</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose a dataframe\n",
    "df_transposed = df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Basic Plotting</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Scatter Plots</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'vehicle_model': ['Tesla Model 3', 'Toyota Camry', 'Honda Civic', 'Ford Mustang', 'Chevy Camaro', 'Nissan Altima', 'Hyundai Elantra', 'Kia Forte', 'Mazda3'],\n",
    "    'fuel_economy': [33, 28, 31, 23, 24, 29, 30, 29, 32],\n",
    "    'engine_size': [2.5, 2.5, 1.5, 5.0, 6.2, 2.5, 2.0, 2.0, 2.5],\n",
    "    'engine_displacement': [1.5, 1.8, 1.4, 4.6, 6.2, 1.8, 1.8, 1.8, 1.8],\n",
    "    'horsepower': [350, 203, 174, 460, 455, 188, 195, 201, 184],\n",
    "    'weight': [1500, 3200, 2800, 3500, 3800, 3200, 3000, 3000, 3000],\n",
    "    'acceleration': [4.4, 8.3, 9.2, 5.2, 4.8, 8.5, 8.8, 9.0, 8.7],\n",
    "    'year': [2022, 2023, 2022, 2023, 2022, 2023, 2022, 2023, 2022],\n",
    "    'origin': ['USA', 'Japan', 'Japan', 'USA', 'USA', 'Japan', 'South Korea', 'South Korea', 'Japan']\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(8, 6))  # Start with creating new plot with specified size\n",
    "plt.scatter(df['engine_size'], df['horsepower'])  # Create scatter plot (x-axis, y-axis)\n",
    "plt.xlabel('Engine Size')\n",
    "plt.ylabel('Horsepower')\n",
    "plt.title('Engine Size vs. Horsepower')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Adding Major/Minor Grid Lines</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(df['engine_size'], df['horsepower'])\n",
    "plt.xlabel('Engine Size')\n",
    "plt.ylabel('Horsepower')\n",
    "plt.title('Engine Size vs. Horsepower')\n",
    "\n",
    "# Set the x-axis tick labels to display floating points\n",
    "plt.xticks(df['engine_size'], labels=df['engine_size'])\n",
    "\n",
    "# Add major and minor grid lines\n",
    "plt.grid(True, which='major', linestyle='-', linewidth=0.5, color='gray')\n",
    "plt.grid(True, which='minor', linestyle='--', linewidth=0.25, color='gray', alpha=0.5)\n",
    "plt.minorticks_on()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Combining multiple Excel sheets into one Data Frame</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sep = pd.read_excel('file1.xlsx', sheet_name='SEPTEMBER', skiprows=3)\n",
    "df_oct = pd.read_excel('file1.xlsx', sheet_name='OCTOBER', skiprows=3)\n",
    "df_nov = pd.read_excel('file1.xlsx', sheet_name='NOVEMBER', skiprows=3)\n",
    "\n",
    "df_sep['MONTH'] = 'September'\n",
    "df_oct['MONTH'] = 'October'\n",
    "df_nov['MONTH'] = 'November'\n",
    "\n",
    "df = pd.concat([df_sep, df_oct, df_nov], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Excluding rows</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('file1.xlsx', skiprows=6)\n",
    "\n",
    "# Exclude all rows except rows 35-60\n",
    "df = df.iloc[35:60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Dealing with unusual encodings</h3>\n",
    "<p>Sometimes files are encoded differently and/or in a different language. In this case, we can use the 'charset' library to detect the encoding, and then call pd.read_csv() with the encoding detected from charset</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from charset_normalizer import detect\n",
    "\n",
    "# Get encoding\n",
    "with open('file1.csv', 'rb') as file:\n",
    "    encoding = detect(file.read())['encoding']\n",
    "\n",
    "# Pass detected encoding to read_csv\n",
    "df = pd.read_csv('Real Estate Mumbai Database - Rgdcvvvh.csv', encoding=encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Method for creating pandas data frame</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_from_file(file_path, skip_rows=None):\n",
    "    if file_path.endswith('.csv'):\n",
    "        if skip_rows is not None:\n",
    "            df = pd.read_csv(file_path, skiprows=skip_rows)\n",
    "        else:\n",
    "            df = pd.read_csv(file_path)\n",
    "    elif file_path.endswith('.xlsx'):\n",
    "        if skip_rows is not None:\n",
    "            df = pd.read_excel(file_path, skiprows=skip_rows)\n",
    "        else:\n",
    "            df = pd.read_excel(file_path)\n",
    "    else:\n",
    "        raise ValueError('File format not supported. Please provide a CSV or Excel file.')\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Method for finding NaNs/NaTs/Null entries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_null_values(df):\n",
    "    if df.empty:\n",
    "        print(\"The DataFrame is empty.\")\n",
    "        return\n",
    "\n",
    "    null_values = df.isnull()\n",
    "\n",
    "    total_null_values = null_values.sum().sum()\n",
    "\n",
    "    if total_null_values == 0:\n",
    "        print(\"There are no null/NaN values in the DataFrame.\")\n",
    "    else:\n",
    "        print(f\"Total number of null/NaN values: {total_null_values}\")\n",
    "\n",
    "        for column in df.columns:\n",
    "            null_rows = df[null_values[column]].index.tolist()\n",
    "            if len(null_rows) > 0:\n",
    "                print(f\"\\nColumn: {column}\")\n",
    "                print(\"Row(s) with null/NaN values:\")\n",
    "                for row in null_rows:\n",
    "                    print(f\"- Row {row}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Method for cleaning values representing currency</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_currency_data(df, remove_whitespace=True, remove_currency=True, remove_commas=True):\n",
    "    cleaned_df = df.copy()\n",
    "\n",
    "    for column in cleaned_df.columns:\n",
    "        if cleaned_df[column].dtype == 'object':\n",
    "            if remove_whitespace:\n",
    "                cleaned_df[column] = cleaned_df[column].str.strip()\n",
    "\n",
    "            if remove_currency:\n",
    "                # Remove currency symbols (e.g., '$', '£', '€')\n",
    "                cleaned_df[column] = cleaned_df[column].str.replace(r'[$£€]', '', regex=True)\n",
    "\n",
    "            if remove_commas:\n",
    "                # Remove commas\n",
    "                cleaned_df[column] = cleaned_df[column].str.replace(',', '')\n",
    "\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Method for obtaining data types of columns</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_data_types(df):\n",
    "    column_info = {}\n",
    "\n",
    "    for col in df.columns:\n",
    "        data_type = df[col].dtype\n",
    "        column_info[col] = str(data_type)\n",
    "    \n",
    "    return column_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from charset_normalizer import detect\n",
    "\n",
    "class TabularDataProcessor:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.df = None\n",
    "\n",
    "\n",
    "    def create_df_from_file(self, skip_rows=None):\n",
    "        try:\n",
    "            if self.file_path.endswith('.csv'):\n",
    "                self.df = pd.read_csv(self.file_path, skiprows=skip_rows)\n",
    "            elif self.file_path.endswith('.xlsx'):\n",
    "                self.df = pd.read_excel(self.file_path, skiprows=skip_rows)\n",
    "            else:\n",
    "                raise ValueError('File format not supported. Please provide a CSV or Excel file.')\n",
    "        except UnicodeDecodeError:\n",
    "            print(f\"Encoding error occurred while reading the file: {self.file_path}\")\n",
    "            print(\"Detecting encoding...\")\n",
    "            with open(self.file_path, 'rb') as file:\n",
    "                result = detect(file.read())\n",
    "            encoding = result.encoding\n",
    "            print(f\"Detected encoding: {encoding}\")\n",
    "            try:\n",
    "                if self.file_path.lower().endswith('.csv'):\n",
    "                    self.df = pd.read_csv(self.file_path, encoding=encoding, skiprows=skip_rows)\n",
    "                elif self.file_path.lower().endswith(('.xls', '.xlsx')):\n",
    "                    self.df = pd.read_excel(self.file_path, skiprows=skip_rows)\n",
    "            except Exception as e:\n",
    "                raise Exception(f\"An error occurred while loading the file with detected encoding: {str(e)}\")\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"File not found: {self.file_path}\")\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"An error occurred while loading the file: {str(e)}\")\n",
    "        \n",
    "\n",
    "    def display_df_info(self):\n",
    "        print(\"DataFrame Info:\")\n",
    "        print(self.df.info())\n",
    "        print(\"\\nDataFrame Head:\")\n",
    "        print(self.df.head().to_markdown(numalign='left', stralign='left'))\n",
    "\n",
    "\n",
    "    def strip_column_names(self):\n",
    "        for column in self.df.columns:\n",
    "            if self.df[column].dtype == 'object':\n",
    "                self.df[column] = self.df[column].astype(str).str.strip()\n",
    "    \n",
    "\n",
    "    def process_currency_values(self, currency_columns=None, int_columns=None, float_columns=None):\n",
    "        if currency_columns:\n",
    "            for column in currency_columns:\n",
    "                if column in self.df.columns:\n",
    "                    self.df[column] = self.df[column].astype(str)\n",
    "                    self.df[column] = self.df[column].str.replace(r'[^0-9.\\-]', '', regex=True)\n",
    "                    self.df[column] = self.df[column].astype(float)\n",
    "                else:\n",
    "                    print(f\"Warning: Column '{column}' not found in the DataFrame.\")\n",
    "\n",
    "        if int_columns:\n",
    "            for column in int_columns:\n",
    "                if column in self.df.columns:\n",
    "                    self.df[column] = self.df[column].astype(int)\n",
    "                else:\n",
    "                    print(f\"Warning: Column '{column}' not found in the DataFrame.\")\n",
    "\n",
    "        if float_columns:\n",
    "            for column in float_columns:\n",
    "                if column in self.df.columns:\n",
    "                    self.df[column] = self.df[column].astype(float)\n",
    "                else:\n",
    "                    print(f\"Warning: Column '{column}' not found in the DataFrame.\")\n",
    "\n",
    "    \n",
    "    def get_processed_df(self):\n",
    "        return self.df\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_vis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
